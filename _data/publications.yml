# For available link types, see publication_buttons variable in _config.yml
  # EXAMPLE:
  # links:
  #   - type: pdf
  #     display: PDF
  #     url: /pdfs/publications/biyik2022aprel.pdf
  #   - type: arxiv
  #     display: arXiv
  #     url: https://arxiv.org/abs/2108.07259
  #   - type: website
  #     display: Website
  #     url: https://aprel.readthedocs.io
  #   - type: code
  #     display: Code
  #     url: https://github.com/Stanford-ILIAD/APReL
  #   - type: video
  #     display: Video
  #     url: https://youtu.be/HvwlBNy3l40
  #   - type: talk
  #     display: Talk
  #     url: https://youtu.be/HExrlibCxdI
  #   - type: doi
  #     display: DOI
  #     url: https://doi.org/10.1109/hri53351.2022.9889650 

  # note: '* denotes equal contribution. † denotes equal advising.'

- title: 'Instructional fingerprinting of large language models.'
  authors: Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen.
  venue: NAACL 2024
  picture: /images/publications/figureprint.png
  topics: LLM Safety
  year: 2024
  links:
    - type: pdf
      display: PDF
      url: https://arxiv.org/pdf/2401.12255
    - type: arxiv
      display: arXiv
      url: https://arxiv.org/abs/2401.12255
    - type: website
      display: Website
      url: https://cnut1648.github.io/Model-Fingerprint/
  bibtex: '@misc{xu2024instructional,
      title={Instructional Fingerprinting of Large Language Models},
      author={Jiashu Xu and Fei Wang and Mingyu Derek Ma and Pang Wei Koh and Chaowei Xiao and Muhao Chen},
      year={2024},
      eprint={2401.12255},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}'

- title: 'AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models.'
  authors: Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao.
  venue: ICLR 2024
  picture: /images/publications/autodan.png
  topics: LLM Safety
  year: 2024
  links:
    - type: pdf
      display: PDF
      url: https://arxiv.org/pdf/2310.04451
    - type: arxiv
      display: arXiv
      url: https://arxiv.org/abs/2310.04451
    - type: code
      display: Code
      url: https://github.com/SheltonLiu-N/AutoDAN
  bibtex: '@inproceedings{
      liu2024autodan,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models},
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=7Jwpw4qKkb}
}'


- title: 'On the exploitability of instruction tuning.'
  authors: Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao†, Tom Goldstein†.
  venue: NeurIPS 2023
  picture: /images/publications/ontheexp.png
  note: '† denotes corresponding author.'
  topics: LLM Safety
  year: 2023
  links:
    - type: pdf
      display: PDF
      url: https://arxiv.org/pdf/2306.17194
    - type: arxiv
      display: arXiv
      url: https://arxiv.org/abs/2306.17194
    - type: code
      display: Code
      url: https://github.com/azshue/AutoPoison
  bibtex: '@inproceedings{shu2023on,
          title={On the Exploitability of Instruction Tuning},
          author={Manli Shu and Jiongxiao Wang and Chen Zhu and Jonas Geiping and Chaowei Xiao and Tom Goldstein},
          booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
          year={2023},
          url={https://openreview.net/forum?id=4AQ4Fnemox}
}'